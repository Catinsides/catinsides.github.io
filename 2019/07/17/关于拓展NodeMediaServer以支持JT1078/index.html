<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 关于拓展NodeMediaServer以支持JT1078 · catinsides.github.io</title><meta name="description" content="关于拓展NodeMediaServer以支持JT1078 - catinsides"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="https://catinsides.github.io/atom.xml" title="catinsides.github.io"><meta name="generator" content="Hexo 7.1.1"><link rel="alternate" href="/atom.xml" title="catinsides.github.io" type="application/atom+xml">
</head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/Catinsides" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">关于拓展NodeMediaServer以支持JT1078</h1><div class="post-info">2019年7月17日</div><div class="post-content"><h3 id="Jul-13-2019"><a href="#Jul-13-2019" class="headerlink" title="Jul. 13, 2019"></a>Jul. 13, 2019</h3><p>可能与最近几月坚持跑步有关，头脑突然灵活了很多。</p>
<p>前几日闲来无事摸鱼时，突然就翻回到了NodeMediaServer（NMS）的代码。从服务启动，到视频的解析推流，大致三到四个文件，脉络清晰。NMS的文件结构给了我很大的启发。我突然就想到，完全可以按照NMS的结构，把JT1078的解析也整合进去。</p>
<p>想到去年年底，第一次接触JT1078，视频拉流推流这些概念的时候，完全是一脸懵比。当时准备在NMS上改造，也是在视频推流之后，在NMS解析视频包的位置进行后续处理。甚至研究了一段时间的RTMP握手，由于设备推流不是RTMP协议，在代码里还要判断，如果是设备推流过来的，要跳过RTMP握手阶段，再推流出去。现在回想起来，甚是痛苦。好在现在知道了如何使用FFmpeg作为推流工具，使得这一功能实现。</p>
<p>今日，我仿照NMS的结构，和前几篇文章提到的FFmpeg命令，主要以FFmpeg推流实现的JT1078解析代码推到了仓库里。明显这不是最优的方案。其中一个很大的问题就是一个通道就要启动三个子进程（视频，音频和合并音视频），一般每台设备会有六个通道，观看一个设备的视频直播时就要启动大量的FFmpeg，相当耗费资源。而且这些子进程管理起来比较麻烦，有可能随时某一个在收不到数据时的进程关闭，就会出现 <strong>EPIPE</strong> 错误。而我理想中的最佳方案并不是这样的。最初，我尝试将设备推流过来的视频和音频数据，分别使用NMS原代码中的RTMP封包函数处理，送到播放者的socket中去，但是并没有成功。尝试几轮，服务端没有报错，看起来成功了，但是播放端并没有数据。未找到原因在哪，就暂时转换思路，使用FFmpeg来实现了。</p>
<p>后来又想到，直接使用NMS的封包函数是不行的。视频数据倒是不需要额外处理，音频数据是G7xx格式的，RTMP并不支持，所以需要转码。看来代码层面的封包和解码还需要研究一段时间。</p>
<p>唉！现在是不能够用代码直接封装音视频包，只得使用FFmpeg命令。我要是懂得音视频解封装，还能吃这个亏？</p>
<h3 id="Jul-16-2019"><a href="#Jul-16-2019" class="headerlink" title="Jul. 16, 2019"></a>Jul. 16, 2019</h3><p>今日，研究了一下FFmpeg的命令，想到可以使用两条输入流（视频和音频）转化成一条输出流（RTMP）的方式实现转码和推流。这样就能够不创造出上一方案中多出来的视频和音频子进程了。在将设备的视频和音频流数据，分别存储下来后，使用FFmpeg命令推流</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg -i test.264 -i test.mp3 -map 0:v -map 1:a -c:v copy -c:a copy -f flv rtmp://xxxx:1935/live/stream_xxxx</span><br></pre></td></tr></table></figure>

<p>命令执行成功，证明了这种方案可能行。于是，我将代码改造为，先将数据缓存，然后使用FFmpeg推流。谁知，实际情况是，缓存数据太小，FFmpeg进程启动后，瞬间就完成了推流，然后关闭了进程。造成的现象就是程序完全没有在（持续）推流。如果FFmpeg随时都要启动的话，有可能会遇到，总将文件从头开始推流的问题。遂暂时搁置了这种方案。</p>
<p>根据上一方案存在的问题，又想到了启动子进程后，可以使用写入 <strong>stdin</strong> 的方式，将数据写入FFmpeg的进程中。但是并没有找到NodeJs写入两条输入流到一个子进程中去的方法。就算是将视频流利用管道符串接到音频流的转码进程中，还是需要有两条输入流。看来这种方案暂时也不行了。</p>
<p>无意中翻到了 <strong>fluent-ffmpeg</strong> 这个库，好像有支持两条输入流的接口，待有时间再测试。</p>
<h3 id="Dec-31-2019"><a href="#Dec-31-2019" class="headerlink" title="Dec. 31, 2019"></a>Dec. 31, 2019</h3><p>万万没想到，在2020以前我能将上面的问题解决。 <del>先忘记fluent-ffmpeg这件事吧</del><br>注: <strong>以下内容适用于Linux系统</strong><br>解决方案仍然是，将视频和音频分流后存储为文件，不同的是文件类别为pipe文件，即命名管道文件(Named Pipe).它遵循先进先出原则(FIFO)，可以像普通文件一样管理。<br>可以使用以下命令创建管道文件:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mkfifo /tmp/one.pipe</span><br><span class="line">$ mkfifo /tmp/two.pipe</span><br></pre></td></tr></table></figure>

<p>然后将程序分离出的视频数据和音频数据像写文件一样写入即可，ffmpeg的进程则从这两个文件中读取数据，再转换成rtmp推流发送出去。<br>ffmpeg命令如下:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ffmpeg -loglevel panic -probesize 32 -re -r 16 -f h264 -i /tmp/one.pipe -f mp3 -i /tmp/two.pipe -map 0:v -map 1:a -c:v copy -c:a aac -strict -2 -preset ultrafast -tune zerolatency -f flv rtmp://xxxx:1935/live/stream_xxxx</span><br></pre></td></tr></table></figure>

<p>读入的文件需要指定格式，如h264和mp3(在上一步中将g726转为了mp3).<br>具体代码实现见我此次提交 <a target="_blank" rel="noopener" href="https://github.com/Catinsides/Node-Media-Server/commit/17be2385e0bc00e4514c504035155d3703299947?diff=split">commit</a></p>
</div></article></div></main><footer><div class="paginator"><a href="/2024/03/28/Hello-Again/" class="prev">PREV</a><a href="/2019/03/29/JT1078%E5%8D%8F%E8%AE%AE%E5%BC%80%E5%8F%91%E4%B9%8B%E5%8F%8C%E5%90%91%E5%AF%B9%E8%AE%B2%E5%90%8E%E8%AE%B0/" class="next">NEXT</a></div><div class="copyright"><p>© 2016 - 2024 <a href="https://catinsides.github.io">catinsides</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>